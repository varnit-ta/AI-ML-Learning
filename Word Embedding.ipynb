{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM from Scrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\varni\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus\n",
    "corpus = [\n",
    "    \"the quick brown fox jumped over the lazy dog\",\n",
    "    \"the dog sat on the mat\",\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the quick red fox jumped over the sleeping cat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Tokenize the text and build vocabulary\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
    "vocabulary = set(word for sentence in tokenized_corpus for word in sentence)\n",
    "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized corpus: [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog'], ['the', 'dog', 'sat', 'on', 'the', 'mat'], ['the', 'cat', 'sat', 'on', 'the', 'mat'], ['the', 'quick', 'red', 'fox', 'jumped', 'over', 'the', 'sleeping', 'cat']]\n",
      "Vocabulary: {'over', 'brown', 'the', 'quick', 'dog', 'fox', 'sat', 'on', 'mat', 'sleeping', 'jumped', 'cat', 'lazy', 'red'}\n",
      "Word to index: {'over': 0, 'brown': 1, 'the': 2, 'quick': 3, 'dog': 4, 'fox': 5, 'sat': 6, 'on': 7, 'mat': 8, 'sleeping': 9, 'jumped': 10, 'cat': 11, 'lazy': 12, 'red': 13}\n",
      "Index to word: {0: 'over', 1: 'brown', 2: 'the', 3: 'quick', 4: 'dog', 5: 'fox', 6: 'sat', 7: 'on', 8: 'mat', 9: 'sleeping', 10: 'jumped', 11: 'cat', 12: 'lazy', 13: 'red'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized corpus:\", tokenized_corpus)\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "print(\"Word to index:\", word2idx)\n",
    "print(\"Index to word:\", idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 2\n",
    "embedding_dim = 50\n",
    "learning_rate = 0.01\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "def generate_training_data(tokenized_corpus, word2idx, window_size):\n",
    "\n",
    "    \"\"\"Generates training data for a word2vec model.\n",
    "    Args:\n",
    "        corpus: A list of sentences, where each sentence is a list of words.\n",
    "        word2idx: A dictionary that maps words to their indices in the vocabulary.\n",
    "        window_size: The size of the context window.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains the index of a center word\n",
    "        and the index of a context word.\n",
    "    \"\"\"\n",
    "\n",
    "    training_data = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        sentence_indices = [word2idx[word] for word in sentence]\n",
    "        for center_word_pos in range(len(sentence_indices)):\n",
    "            center_word_idx = sentence_indices[center_word_pos]\n",
    "            for w in range(-window_size, window_size + 1):\n",
    "                context_word_pos = center_word_pos + w\n",
    "                if context_word_pos < 0 or context_word_pos >= len(sentence_indices) or context_word_pos == center_word_pos:\n",
    "                    continue\n",
    "                context_word_idx = sentence_indices[context_word_pos]\n",
    "                training_data.append((center_word_idx, context_word_idx))\n",
    "                \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = generate_training_data(tokenized_corpus, word2idx, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (3, 1),\n",
       " (3, 5),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 5),\n",
       " (1, 10),\n",
       " (5, 3),\n",
       " (5, 1),\n",
       " (5, 10),\n",
       " (5, 0),\n",
       " (10, 1),\n",
       " (10, 5),\n",
       " (10, 0),\n",
       " (10, 2),\n",
       " (0, 5),\n",
       " (0, 10),\n",
       " (0, 2),\n",
       " (0, 12),\n",
       " (2, 10),\n",
       " (2, 0),\n",
       " (2, 12),\n",
       " (2, 4),\n",
       " (12, 0),\n",
       " (12, 2),\n",
       " (12, 4),\n",
       " (4, 2),\n",
       " (4, 12),\n",
       " (2, 4),\n",
       " (2, 6),\n",
       " (4, 2),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (6, 2),\n",
       " (6, 4),\n",
       " (6, 7),\n",
       " (6, 2),\n",
       " (7, 4),\n",
       " (7, 6),\n",
       " (7, 2),\n",
       " (7, 8),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (8, 7),\n",
       " (8, 2),\n",
       " (2, 11),\n",
       " (2, 6),\n",
       " (11, 2),\n",
       " (11, 6),\n",
       " (11, 7),\n",
       " (6, 2),\n",
       " (6, 11),\n",
       " (6, 7),\n",
       " (6, 2),\n",
       " (7, 11),\n",
       " (7, 6),\n",
       " (7, 2),\n",
       " (7, 8),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (8, 7),\n",
       " (8, 2),\n",
       " (2, 3),\n",
       " (2, 13),\n",
       " (3, 2),\n",
       " (3, 13),\n",
       " (3, 5),\n",
       " (13, 2),\n",
       " (13, 3),\n",
       " (13, 5),\n",
       " (13, 10),\n",
       " (5, 3),\n",
       " (5, 13),\n",
       " (5, 10),\n",
       " (5, 0),\n",
       " (10, 13),\n",
       " (10, 5),\n",
       " (10, 0),\n",
       " (10, 2),\n",
       " (0, 5),\n",
       " (0, 10),\n",
       " (0, 2),\n",
       " (0, 9),\n",
       " (2, 10),\n",
       " (2, 0),\n",
       " (2, 9),\n",
       " (2, 11),\n",
       " (9, 0),\n",
       " (9, 2),\n",
       " (9, 11),\n",
       " (11, 2),\n",
       " (11, 9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "W1 = np.random.rand(len(vocabulary), embedding_dim)\n",
    "W2 = np.random.rand(embedding_dim, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Softmax\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 160.7800452392337\n",
      "Epoch: 200, Loss: 160.72244895560266\n",
      "Epoch: 300, Loss: 160.66923771321703\n",
      "Epoch: 400, Loss: 160.620070536631\n",
      "Epoch: 500, Loss: 160.574639166864\n",
      "Epoch: 600, Loss: 160.53266315510993\n",
      "Epoch: 700, Loss: 160.49388595249692\n",
      "Epoch: 800, Loss: 160.45807179221922\n",
      "Epoch: 900, Loss: 160.4250031957297\n",
      "Epoch: 1000, Loss: 160.39447896588618\n",
      "Epoch: 1100, Loss: 160.3663125568946\n",
      "Epoch: 1200, Loss: 160.34033073371995\n",
      "Epoch: 1300, Loss: 160.31637245264616\n",
      "Epoch: 1400, Loss: 160.29428791022016\n",
      "Epoch: 1500, Loss: 160.27393772037405\n",
      "Epoch: 1600, Loss: 160.25519218947457\n",
      "Epoch: 1700, Loss: 160.2379306668417\n",
      "Epoch: 1800, Loss: 160.22204095427463\n",
      "Epoch: 1900, Loss: 160.20741876267385\n",
      "Epoch: 2000, Loss: 160.1939672072356\n",
      "Epoch: 2100, Loss: 160.18159633518485\n",
      "Epoch: 2200, Loss: 160.17022268179485\n",
      "Epoch: 2300, Loss: 160.15976885170997\n",
      "Epoch: 2400, Loss: 160.1501631234466\n",
      "Epoch: 2500, Loss: 160.1413390755351\n",
      "Epoch: 2600, Loss: 160.13323523313628\n",
      "Epoch: 2700, Loss: 160.12579473420126\n",
      "Epoch: 2800, Loss: 160.1189650143791\n",
      "Epoch: 2900, Loss: 160.11269750994896\n",
      "Epoch: 3000, Loss: 160.10694737808922\n",
      "Epoch: 3100, Loss: 160.10167323380574\n",
      "Epoch: 3200, Loss: 160.09683690284174\n",
      "Epoch: 3300, Loss: 160.09240318988842\n",
      "Epoch: 3400, Loss: 160.08833966141427\n",
      "Epoch: 3500, Loss: 160.08461644242354\n",
      "Epoch: 3600, Loss: 160.08120602646645\n",
      "Epoch: 3700, Loss: 160.07808309822337\n",
      "Epoch: 3800, Loss: 160.07522436800292\n",
      "Epoch: 3900, Loss: 160.0726084175037\n",
      "Epoch: 4000, Loss: 160.0702155562106\n",
      "Epoch: 4100, Loss: 160.0680276878167\n",
      "Epoch: 4200, Loss: 160.066028186079\n",
      "Epoch: 4300, Loss: 160.0642017795469\n",
      "Epoch: 4400, Loss: 160.06253444461748\n",
      "Epoch: 4500, Loss: 160.0610133064006\n",
      "Epoch: 4600, Loss: 160.05962654690015\n",
      "Epoch: 4700, Loss: 160.05836332003807\n",
      "Epoch: 4800, Loss: 160.05721367307606\n",
      "Epoch: 4900, Loss: 160.05616847400802\n",
      "Epoch: 5000, Loss: 160.05521934452\n",
      "Epoch: 5100, Loss: 160.05435859814006\n",
      "Epoch: 5200, Loss: 160.053579183213\n",
      "Epoch: 5300, Loss: 160.05287463036458\n",
      "Epoch: 5400, Loss: 160.05223900413205\n",
      "Epoch: 5500, Loss: 160.05166685846163\n",
      "Epoch: 5600, Loss: 160.05115319578798\n",
      "Epoch: 5700, Loss: 160.05069342943358\n",
      "Epoch: 5800, Loss: 160.05028334907442\n",
      "Epoch: 5900, Loss: 160.04991908904296\n",
      "Epoch: 6000, Loss: 160.04959709924947\n",
      "Epoch: 6100, Loss: 160.04931411851936\n",
      "Epoch: 6200, Loss: 160.04906715015562\n",
      "Epoch: 6300, Loss: 160.04885343955235\n",
      "Epoch: 6400, Loss: 160.04867045369593\n",
      "Epoch: 6500, Loss: 160.04851586239923\n",
      "Epoch: 6600, Loss: 160.04838752113147\n",
      "Epoch: 6700, Loss: 160.04828345531132\n",
      "Epoch: 6800, Loss: 160.04820184594286\n",
      "Epoch: 6900, Loss: 160.04814101648375\n",
      "Epoch: 7000, Loss: 160.04809942084194\n",
      "Epoch: 7100, Loss: 160.04807563240664\n",
      "Epoch: 7200, Loss: 160.04806833402594\n",
      "Epoch: 7300, Loss: 160.0480763088497\n",
      "Epoch: 7400, Loss: 160.04809843196693\n",
      "Epoch: 7500, Loss: 160.04813366276542\n",
      "Epoch: 7600, Loss: 160.04818103795435\n",
      "Epoch: 7700, Loss: 160.04823966519206\n",
      "Epoch: 7800, Loss: 160.04830871726523\n",
      "Epoch: 7900, Loss: 160.04838742677302\n",
      "Epoch: 8000, Loss: 160.0484750812718\n",
      "Epoch: 8100, Loss: 160.04857101883937\n",
      "Epoch: 8200, Loss: 160.04867462402268\n",
      "Epoch: 8300, Loss: 160.0487853241354\n",
      "Epoch: 8400, Loss: 160.04890258587386\n",
      "Epoch: 8500, Loss: 160.0490259122246\n",
      "Epoch: 8600, Loss: 160.04915483963623\n",
      "Epoch: 8700, Loss: 160.04928893543382\n",
      "Epoch: 8800, Loss: 160.0494277954532\n",
      "Epoch: 8900, Loss: 160.04957104187653\n",
      "Epoch: 9000, Loss: 160.04971832125102\n",
      "Epoch: 9100, Loss: 160.0498693026754\n",
      "Epoch: 9200, Loss: 160.05002367613693\n",
      "Epoch: 9300, Loss: 160.05018115098974\n",
      "Epoch: 9400, Loss: 160.05034145455804\n",
      "Epoch: 9500, Loss: 160.05050433085523\n",
      "Epoch: 9600, Loss: 160.0506695394092\n",
      "Epoch: 9700, Loss: 160.05083685418307\n",
      "Epoch: 9800, Loss: 160.05100606258335\n",
      "Epoch: 9900, Loss: 160.05117696454911\n",
      "Epoch: 10000, Loss: 160.0513493717131\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for center_word_idx, context_word_idx in training_data:\n",
    "        # Forward pass\n",
    "        h = W1[center_word_idx]\n",
    "        u = np.dot(W2.T, h)\n",
    "        y_pred = softmax(u)\n",
    "        \n",
    "        # Calculate error\n",
    "        e = np.zeros(len(vocabulary))\n",
    "        e[context_word_idx] = 1\n",
    "        error = e - y_pred\n",
    "        \n",
    "        # Backpropagation\n",
    "        dW2 = np.outer(h, error)\n",
    "        dW1 = np.dot(W2, error)\n",
    "        \n",
    "        W1[center_word_idx] += learning_rate * dW1\n",
    "        W2 += learning_rate * dW2\n",
    "\n",
    "        loss += -np.log(y_pred[context_word_idx])\n",
    "        \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch: {epoch + 1}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word embeddings\n",
    "word_embeddings = {word: W1[idx] for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'over': array([ 0.2643237 ,  0.15359734,  0.2566751 , -0.49269645,  0.25349305,\n",
      "       -0.36274086,  0.07544404,  0.01349164,  0.04836143, -0.17382901,\n",
      "       -0.45694518, -0.30115153,  0.05815846,  0.79509194, -0.13766509,\n",
      "        0.70968481, -0.07543288,  0.01416559, -0.36577318,  0.0248995 ,\n",
      "       -0.37730451,  0.02311338, -0.24298693,  0.09364391,  0.20392836,\n",
      "        0.69879893,  0.89376086,  0.28696915,  0.21500321,  0.13875812,\n",
      "       -0.36617171,  0.57249123,  0.21578237, -0.11820204,  0.07730346,\n",
      "       -0.74920352,  0.19502251,  0.96743235,  0.59802843,  0.09031106,\n",
      "        0.16748159,  0.58650932,  0.12622882,  0.38731539,  0.61492919,\n",
      "       -0.18646264, -0.25414947, -0.49893071,  0.38759397,  0.15442185]), 'brown': array([ 0.41553012,  0.72048019,  0.4980261 , -0.18519245,  0.41900809,\n",
      "       -0.27936133,  0.5855726 , -0.09478651, -0.01247578,  0.235049  ,\n",
      "       -0.12090455, -0.30194405,  0.25679069,  1.17407469, -0.10311129,\n",
      "        0.86244504,  0.05790593,  0.47579246, -0.09240069,  0.63143567,\n",
      "        0.30285665,  0.34900886,  0.16648035, -0.52920344,  0.00615022,\n",
      "        0.33923862,  0.28075349,  0.08376824,  0.33741245,  0.56190045,\n",
      "       -0.12337831,  0.56668637, -0.09014332, -0.42708862,  0.25016142,\n",
      "       -0.30555526,  0.96818591,  0.48183309,  0.52589772,  0.55250834,\n",
      "        0.10848388,  0.07439007, -0.28554821,  0.31540989,  0.37979224,\n",
      "        0.10001306,  0.11354871,  0.5685367 ,  0.10814928,  0.50530294]), 'the': array([-0.01895727, -0.16094013, -0.17573141, -0.14529326, -0.11018527,\n",
      "       -0.0022348 , -0.24114851, -0.30313532, -0.40654664, -0.09810438,\n",
      "        0.03079992, -0.28637488, -0.36450874, -0.33453823, -0.09461578,\n",
      "       -0.36716671, -0.06518154, -0.10698107, -0.1024187 , -0.27404901,\n",
      "       -0.03811127,  0.03739521, -0.356163  , -0.21799226, -0.26142588,\n",
      "       -0.38300983, -0.21788036, -0.21476495, -0.10600639, -0.21386817,\n",
      "       -0.0770476 , -0.36020586, -0.11786664, -0.25810666, -0.01821367,\n",
      "        0.36471355, -0.41645825, -0.06044154, -0.46106241, -0.02677669,\n",
      "       -0.09247373, -0.16145277, -0.15353324,  0.11925563,  0.03457687,\n",
      "       -0.17570895, -0.03898745, -0.05998854, -0.37682377, -0.11832753]), 'quick': array([-0.26574224,  0.21957974,  0.84264333, -0.08608717,  0.38374986,\n",
      "        0.42782064, -0.00470495,  0.32104061,  0.33934606,  0.7268828 ,\n",
      "        0.15861777,  0.67201287,  0.61957092,  0.06996624, -0.64303642,\n",
      "        0.30270857,  0.47293001, -0.31395084,  0.36989875,  0.00959983,\n",
      "       -0.075962  , -0.02936536,  0.37686843,  0.48294863,  0.57263854,\n",
      "        0.97538035, -0.12140645,  0.30535977, -0.40868682, -0.18615337,\n",
      "        0.19833643,  0.43978349,  0.10993562,  0.42140568,  0.13755728,\n",
      "       -0.16293289,  0.37411986,  0.10882569,  0.62018188,  0.21204182,\n",
      "       -0.16454332,  0.18309406,  0.55622506, -0.20657779, -0.10984142,\n",
      "        0.18866468,  0.26289258, -0.14054115,  0.79878818, -0.37830776]), 'dog': array([ 1.0936654 , -0.16931659,  0.13122558,  0.43675274,  0.35678158,\n",
      "        0.26731404,  0.67046523,  0.52620242,  0.89664917,  0.26068415,\n",
      "       -0.34802563, -0.20594606,  0.39066266,  0.14854136,  0.28613765,\n",
      "       -0.88301352,  1.15473967,  0.38487193, -0.099953  ,  0.38331498,\n",
      "       -0.44315636, -0.32488206,  0.22492792, -0.21790854,  0.22726502,\n",
      "       -0.24061452,  0.56771513,  0.28305294,  0.76240844, -0.20095919,\n",
      "        0.14663351, -0.46490088,  0.45992351,  0.41652145, -0.03010106,\n",
      "        0.12200613, -0.22376563,  0.66912019, -0.18378603, -0.11150986,\n",
      "       -0.03242114,  0.49920473,  0.64375434,  0.78514953,  0.25904457,\n",
      "        0.25530656, -0.25288737, -0.33551519,  0.35914986,  0.05015339]), 'fox': array([ 0.01831379,  0.58448798,  0.15285009, -0.42564737,  0.15225811,\n",
      "        0.46818358,  0.07030822, -0.95331686, -0.65729303, -0.09582687,\n",
      "        0.28215245, -0.3056365 , -0.20186863,  0.00416682, -0.82622474,\n",
      "        0.17339658,  0.66302773,  0.19314672, -0.04388964,  0.20477607,\n",
      "        0.24070371,  0.42661908, -0.6594665 , -0.31608241, -0.60313473,\n",
      "       -0.35989953, -0.4850273 ,  0.00469072, -0.18161022, -0.35544409,\n",
      "       -0.05820931,  0.23940788, -0.49350037, -0.42298908,  0.29223982,\n",
      "        0.77900174,  0.12222932, -0.32331341, -0.00915391,  0.59924467,\n",
      "       -0.23090588, -0.31632576,  0.01619256,  0.05545065,  0.15616294,\n",
      "        0.02915977,  0.17646549,  0.38089326, -0.0385311 , -0.0535516 ]), 'sat': array([-0.15716862, -0.10802586,  0.3267146 ,  0.763195  ,  0.41974245,\n",
      "       -0.64823827, -0.9751365 ,  0.91585326,  0.61866119,  0.29775239,\n",
      "        1.14093529, -0.17782554, -0.02743415, -0.12509183,  0.45462767,\n",
      "        0.00370116, -0.47525392,  0.03320912,  0.31376858,  0.54564108,\n",
      "        0.01701148,  0.2419764 ,  0.48793789,  0.04240623,  0.60070749,\n",
      "        0.21038031,  0.4822881 ,  0.30316681,  0.20720579, -0.06084758,\n",
      "        0.51276407, -0.01755678,  0.3366968 ,  0.36682389, -0.24471659,\n",
      "        0.07246904,  0.06116278,  0.60502598, -0.09264087,  0.4888102 ,\n",
      "       -0.17483947, -0.03452107, -0.125373  ,  0.27867364,  0.17079158,\n",
      "        0.14417549,  0.05706636,  0.34216724, -0.2335891 , -0.31148139]), 'on': array([ 2.79699812e-01, -4.10655429e-01,  3.58928376e-01,  7.73250411e-01,\n",
      "        1.69146096e-01, -4.85870666e-02,  9.35209505e-02,  5.45567203e-01,\n",
      "       -2.45299878e-01,  1.10371086e+00, -1.16628639e-01,  4.62006165e-01,\n",
      "        1.06186731e-01,  1.49901484e-02,  8.50518757e-01, -1.77278076e-01,\n",
      "       -3.79351107e-01, -2.48914887e-01,  5.32673524e-01, -4.25529007e-01,\n",
      "        2.97488113e-01,  1.67349197e-01,  8.02443364e-01,  8.51304974e-02,\n",
      "        7.89068609e-01,  5.33105072e-01, -5.13883118e-04, -3.33397373e-01,\n",
      "        3.02414511e-01,  6.56177703e-01,  5.75812996e-02, -1.24551650e-01,\n",
      "        4.17578812e-01,  1.14297844e-01,  3.27689033e-01,  4.26524671e-01,\n",
      "        2.23113678e-01,  5.53794737e-01, -2.69163819e-01, -1.70596624e-01,\n",
      "        2.69651915e-01,  1.96917452e-01, -2.51164639e-01,  7.97442046e-01,\n",
      "       -3.13071785e-02, -1.66435045e-01,  4.51411908e-01,  2.27390459e-01,\n",
      "       -4.48036894e-01,  2.51006148e-01]), 'mat': array([-5.72299055e-02,  3.67129602e-01,  1.82392373e-01,  4.74316162e-01,\n",
      "        2.19146090e-01, -4.52014547e-01, -2.73281914e-01,  5.21277308e-01,\n",
      "        1.33822226e+00,  3.85108589e-01,  9.19325062e-01, -2.03114403e-01,\n",
      "        3.63772809e-01, -1.03657839e-02,  2.34928732e-01, -6.18925909e-02,\n",
      "        1.88723799e-01,  8.36957239e-02, -1.34707316e-01,  1.04647157e+00,\n",
      "       -1.06686249e-01, -2.49757065e-01,  3.81804376e-01,  1.20394855e-01,\n",
      "        9.67830785e-01, -3.54665196e-02,  6.15300986e-01,  5.53700439e-01,\n",
      "        5.11645468e-01, -3.27959998e-01,  8.74706242e-01, -6.55382768e-02,\n",
      "        3.00846216e-01,  8.34333556e-01, -1.72093014e-02,  7.58216193e-02,\n",
      "        1.05188975e-01,  4.24628763e-01,  9.74903468e-02,  4.67650655e-01,\n",
      "        2.06679857e-01,  7.53731303e-02,  6.09124024e-01,  8.90886132e-04,\n",
      "        2.72490472e-01,  2.46273157e-01, -5.34848605e-01,  6.74932952e-01,\n",
      "        6.45757275e-01, -2.79933866e-01]), 'sleeping': array([ 3.73120674e-01, -2.39245272e-01,  3.53236881e-02,  7.08620505e-01,\n",
      "        4.80132336e-01,  9.33085696e-01, -3.02567735e-01,  1.06657682e+00,\n",
      "        4.04320137e-01, -4.80425808e-01,  1.05070393e+00,  1.61252252e-01,\n",
      "        2.16762956e-01, -1.33709657e-01,  1.19496171e+00,  6.31171325e-02,\n",
      "       -6.26079614e-04,  5.89231640e-01,  1.02841799e+00, -3.27737131e-01,\n",
      "       -7.74002109e-03,  4.12233449e-01,  4.16057926e-01,  7.94580522e-01,\n",
      "       -2.69412562e-01, -4.07749465e-01,  1.31461207e-01,  6.31885463e-01,\n",
      "        7.78416253e-01,  2.76801996e-01,  1.75134825e-01,  4.15572613e-01,\n",
      "        6.48225570e-01,  2.43098784e-02, -2.98985990e-01,  3.97451888e-01,\n",
      "        5.00669441e-01, -3.57835993e-01,  3.49785411e-02,  7.67767268e-01,\n",
      "        1.86084243e-01,  2.67673730e-01, -1.51934803e-01,  1.67793118e-01,\n",
      "       -5.16301763e-02,  9.08678348e-01,  1.28183702e+00, -3.77539410e-01,\n",
      "       -2.24838123e-01,  5.86273600e-01]), 'jumped': array([ 0.00743282,  0.19116789,  0.30055618,  0.38263367,  0.28735371,\n",
      "        0.7752013 ,  0.14135199,  0.12064931, -0.04089235, -0.12502126,\n",
      "        0.22071515,  0.69760837,  0.41236993, -0.02064174, -0.25705301,\n",
      "        0.5378844 ,  0.6833188 ,  0.16761558,  0.64855443,  0.25722906,\n",
      "        0.06011427,  0.35812059,  0.11890601,  0.72453834, -0.04578208,\n",
      "        0.61098782, -0.03286693,  0.46811896, -0.05409958, -0.03246345,\n",
      "       -0.05993622,  0.88177277,  0.05370932,  0.34068169,  0.25531249,\n",
      "        0.18993665,  0.41324722, -0.13496056,  0.65677123,  0.27239908,\n",
      "       -0.18099813,  0.26442786,  0.36409042, -0.04503618, -0.23087009,\n",
      "        0.44987957,  0.59655692, -0.23684111,  0.50604296, -0.0758861 ]), 'cat': array([ 0.57713416, -0.20959339, -0.18560631, -0.13105006,  0.63708181,\n",
      "        0.125699  ,  0.55799877, -0.15875737,  0.61963471,  0.11046855,\n",
      "        0.09790606, -0.39934519,  0.25497045,  0.1408785 ,  0.59336902,\n",
      "        0.1425739 ,  0.37755721, -0.13861275,  0.07532961, -0.23546   ,\n",
      "       -0.1056276 , -0.43157094, -0.01295735,  0.21274854,  0.78654157,\n",
      "        0.14014977,  0.87799459,  0.3965657 ,  0.59288298,  0.06943483,\n",
      "        0.78978426, -0.31715294, -0.08792759,  1.01171643,  0.69763015,\n",
      "        0.60042588, -0.30076173,  0.32347121, -0.61713965, -0.32762593,\n",
      "        0.48705108,  0.82002225,  0.35518485,  0.64937391,  0.66540488,\n",
      "        0.05506003, -0.22470692,  0.13653021,  0.59694487, -0.05874811]), 'lazy': array([ 0.14411049, -0.1839555 , -0.29595233,  1.89100375, -0.01357752,\n",
      "        0.04391662, -0.14045195,  0.18028614, -0.56335496, -0.25267748,\n",
      "        0.47092404,  0.75843136, -0.16285897, -0.42707658,  0.80151418,\n",
      "        0.51427423,  0.07975676,  0.34164573,  0.8621256 ,  0.90007095,\n",
      "        0.51202012,  0.7788763 ,  0.32795834,  0.55465255,  0.22922624,\n",
      "        0.33247726,  0.31324927,  0.41888785,  0.16314809,  0.6667456 ,\n",
      "        0.04719779,  0.8537046 ,  0.11390592,  0.52743797,  0.50926768,\n",
      "        0.93606224,  0.22759882,  0.38217982,  0.16598627, -0.03527902,\n",
      "       -0.18304937,  0.28383002, -0.30716267,  0.60737466, -0.52795029,\n",
      "        0.36588926,  0.51953558,  0.39038875, -0.38993888, -0.02678499]), 'red': array([ 0.38764879,  0.61028875,  0.44521622, -0.15251547,  0.41557232,\n",
      "       -0.28011631,  0.51079185, -0.12921264,  0.01873358,  0.35585173,\n",
      "       -0.21124557, -0.25367113,  0.19247529,  1.15140436, -0.13597218,\n",
      "        0.90314656,  0.091694  ,  0.50671052, -0.18670132,  0.55849538,\n",
      "        0.40629442,  0.24674279,  0.13837677, -0.53588581,  0.03837849,\n",
      "        0.25791845,  0.38429303,  0.16693949,  0.29800451,  0.61868341,\n",
      "       -0.15373364,  0.60295812, -0.05789992, -0.3768043 ,  0.14694039,\n",
      "       -0.20182229,  1.01171306,  0.40221134,  0.64430359,  0.56601543,\n",
      "        0.03113822,  0.00464375, -0.28015214,  0.38438088,  0.43942013,\n",
      "        0.12341509,  0.08603751,  0.56583422,  0.12595572,  0.50126962])}\n"
     ]
    }
   ],
   "source": [
    "print(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus\n",
    "corpus = [\n",
    "    \"the quick brown fox jumped over the lazy dog\",\n",
    "    \"the dog sat on the mat\",\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the quick red fox jumped over the sleeping cat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embedding_dim = 50\n",
    "max_length = max(len(sequence) for sequence in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\varni\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\varni\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding layer weights\n",
    "embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print word embeddings\n",
    "word_embeddings = {word: embeddings[idx] for word, idx in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': array([-0.04612049, -0.01190308, -0.00153064, -0.01120682, -0.03748507,\n",
      "        0.00288481, -0.01680446,  0.04362172,  0.02980744, -0.04893311,\n",
      "        0.04205172, -0.04865813, -0.04556816, -0.02228706,  0.03424952,\n",
      "       -0.00112004,  0.02273047,  0.03050229, -0.00623054, -0.02094885,\n",
      "        0.04634091, -0.01049602,  0.01203208,  0.01687162,  0.01887866,\n",
      "       -0.02861352, -0.03881355,  0.04917821, -0.00909869, -0.01181167,\n",
      "       -0.01551112,  0.01500956, -0.02353489,  0.04423911,  0.04411631,\n",
      "        0.0218701 ,  0.02088172,  0.03352297,  0.01336863,  0.03856951,\n",
      "       -0.03614985, -0.02435851, -0.02646753,  0.02696675,  0.02806308,\n",
      "       -0.03035482,  0.01249006,  0.03066972,  0.02265425,  0.02730176],\n",
      "      dtype=float32), 'quick': array([-0.01442453,  0.01459267, -0.00989127, -0.02025933,  0.02713529,\n",
      "        0.03997696,  0.02862414, -0.03576346, -0.02210573, -0.04239181,\n",
      "        0.04378546, -0.02323896,  0.01567811, -0.01853814,  0.01903195,\n",
      "       -0.02118861,  0.03006964,  0.01755134,  0.02700702, -0.04912911,\n",
      "        0.01005722, -0.0081825 ,  0.0300061 , -0.00610807, -0.01255363,\n",
      "       -0.01338987,  0.03229753, -0.01514141, -0.01726114,  0.03384386,\n",
      "        0.00550152,  0.01968565, -0.00799669, -0.04066358,  0.02210442,\n",
      "        0.00998311, -0.03805144,  0.00488641, -0.00053317,  0.00576742,\n",
      "        0.04978854, -0.04819905,  0.041244  , -0.03261396,  0.04992876,\n",
      "       -0.03160612,  0.00139978, -0.02085464,  0.01499537, -0.00155476],\n",
      "      dtype=float32), 'fox': array([ 0.02600428, -0.02099629, -0.04098744, -0.03986339, -0.048684  ,\n",
      "        0.02922085,  0.00479434, -0.004407  , -0.02358295,  0.0395977 ,\n",
      "       -0.02906934,  0.00090951, -0.02508081,  0.02446492,  0.04005636,\n",
      "       -0.0463537 , -0.02055186,  0.00456283,  0.03721757, -0.04010497,\n",
      "       -0.04424231,  0.01786408,  0.0394575 , -0.03420974,  0.04653427,\n",
      "        0.04699756, -0.02290279, -0.03660896, -0.02779569,  0.047878  ,\n",
      "        0.0257288 ,  0.01478492,  0.02591402, -0.01011431, -0.00894045,\n",
      "       -0.00670497, -0.03348513, -0.02668188,  0.01625574,  0.0395548 ,\n",
      "       -0.02743889, -0.03538771, -0.02537234,  0.04834724,  0.02134284,\n",
      "       -0.00039715, -0.04945582,  0.01833377, -0.02944517,  0.03382112],\n",
      "      dtype=float32), 'jumped': array([ 0.01791367, -0.00297561, -0.00208598, -0.0325392 , -0.00163876,\n",
      "        0.00010712, -0.01879572, -0.02327112, -0.03682961,  0.02050275,\n",
      "       -0.01692895,  0.0454146 ,  0.02571504,  0.02271262, -0.04661205,\n",
      "        0.02074654,  0.04085601,  0.01027616,  0.02203503,  0.02686563,\n",
      "       -0.0249372 , -0.02191897, -0.04867543, -0.02311257,  0.01549331,\n",
      "       -0.04810091,  0.04429683, -0.01031579,  0.01632183, -0.04677001,\n",
      "        0.03917516,  0.04579834,  0.02295755,  0.0359344 ,  0.04619587,\n",
      "        0.00606173, -0.04804806, -0.03294156,  0.02342125, -0.02485354,\n",
      "        0.03820724, -0.00793903, -0.04320545, -0.04779262, -0.01035462,\n",
      "       -0.02362682, -0.01717389, -0.04703515, -0.04889842, -0.04062623],\n",
      "      dtype=float32), 'over': array([ 0.04548942,  0.03576023, -0.01815113, -0.04217789,  0.02586503,\n",
      "       -0.0279742 , -0.04062741, -0.02832835, -0.03193875, -0.0120756 ,\n",
      "       -0.03911648,  0.0198668 , -0.0124134 ,  0.0434796 ,  0.02241298,\n",
      "        0.01521948,  0.03518755, -0.04686033, -0.01781248,  0.041705  ,\n",
      "        0.00109758,  0.00651259,  0.03170116, -0.04290915,  0.03721358,\n",
      "        0.01356262, -0.0283211 , -0.04562662,  0.00772889, -0.03607538,\n",
      "        0.04649888,  0.00160677,  0.03753055,  0.03928969, -0.04025447,\n",
      "       -0.02199607,  0.01618875, -0.0286164 , -0.00231819,  0.02635051,\n",
      "       -0.01602142,  0.00034537, -0.00366694,  0.00748545,  0.02691301,\n",
      "        0.0244044 , -0.0404922 , -0.00861385, -0.03150143, -0.04407267],\n",
      "      dtype=float32), 'dog': array([ 0.03765458,  0.03922266, -0.03496806,  0.02499964, -0.0388866 ,\n",
      "       -0.01103498,  0.0330942 , -0.00111747,  0.03766229, -0.01851751,\n",
      "       -0.02106687,  0.03845872,  0.00050204, -0.00037614, -0.01016809,\n",
      "       -0.02824103,  0.02904077, -0.01065881,  0.02947594,  0.02750626,\n",
      "       -0.04659588, -0.03539   ,  0.01768767, -0.01567533, -0.02877012,\n",
      "        0.02104559,  0.03717141, -0.0409049 , -0.04726703,  0.02874304,\n",
      "        0.04143364,  0.02888478, -0.01584581,  0.00528759,  0.04626641,\n",
      "       -0.00111109,  0.00835222,  0.00290383,  0.03284699,  0.03749621,\n",
      "        0.01705505, -0.00800928, -0.02225407,  0.04745511,  0.02631784,\n",
      "        0.00736367, -0.02358052, -0.02838352,  0.04332646, -0.03025712],\n",
      "      dtype=float32), 'sat': array([-0.04100406, -0.04919093, -0.0087998 , -0.00642973, -0.01783597,\n",
      "        0.03896178,  0.03273852,  0.01777252,  0.04927819, -0.03768329,\n",
      "       -0.01144189,  0.02793385,  0.01458676, -0.03796114,  0.03056074,\n",
      "       -0.02545462, -0.04434818,  0.03800916, -0.00043873,  0.00979114,\n",
      "        0.02473458, -0.02265775, -0.04876664, -0.01182454, -0.03989435,\n",
      "        0.01416408, -0.04655234,  0.00620181,  0.0267644 ,  0.00950785,\n",
      "       -0.02617084, -0.04661151, -0.04512141,  0.00231527, -0.01291402,\n",
      "        0.00133188,  0.01920989,  0.02673903, -0.03545283, -0.02130524,\n",
      "       -0.03523231,  0.02000662,  0.04524643,  0.04058674,  0.04637143,\n",
      "        0.01065602, -0.03569148, -0.03784504,  0.00356698,  0.00196368],\n",
      "      dtype=float32), 'on': array([ 0.03850964, -0.02479656, -0.04934938, -0.00283305, -0.01360748,\n",
      "        0.00067538,  0.00017498, -0.00919827, -0.04552153,  0.02085565,\n",
      "       -0.04389188,  0.02109222,  0.04394319, -0.04706377,  0.04893938,\n",
      "       -0.04011431, -0.03244819,  0.0463756 ,  0.0091031 , -0.03208846,\n",
      "        0.04140398,  0.02601434, -0.01171451, -0.04057192,  0.00895951,\n",
      "        0.03062754,  0.03559737, -0.02713921,  0.02858713, -0.01962014,\n",
      "        0.04402676,  0.00882288,  0.00643442, -0.0341046 , -0.01283243,\n",
      "        0.04375391, -0.03959116, -0.0191518 , -0.02881341,  0.02276022,\n",
      "        0.01906791,  0.03981702, -0.04753873,  0.00750033, -0.01468781,\n",
      "       -0.03590444, -0.04583561, -0.01443388, -0.03358568, -0.02336848],\n",
      "      dtype=float32), 'mat': array([ 0.03855925, -0.04258772,  0.0016989 , -0.00977044,  0.00987998,\n",
      "       -0.03219821,  0.00341387, -0.03084656, -0.03367212,  0.04559736,\n",
      "        0.03583712,  0.00580156,  0.03600954,  0.04907861, -0.01018687,\n",
      "       -0.00779011,  0.00785745, -0.030575  , -0.01285005, -0.03807664,\n",
      "        0.04157908,  0.00032184, -0.02710362, -0.03461157, -0.01708484,\n",
      "        0.03643185, -0.01672046, -0.03384882, -0.04664302,  0.03534213,\n",
      "       -0.01352958, -0.03288748,  0.00249524,  0.04013938,  0.02295265,\n",
      "       -0.0402403 , -0.03982414,  0.02555771,  0.0292269 ,  0.03537942,\n",
      "       -0.00084547,  0.01262276, -0.01821443, -0.01364112,  0.02416578,\n",
      "        0.00100995,  0.036564  , -0.00877549,  0.02573451,  0.03932282],\n",
      "      dtype=float32), 'cat': array([ 0.01070794,  0.04657384, -0.02355166, -0.01651645,  0.04617051,\n",
      "       -0.04501451,  0.00183498, -0.02341225,  0.04848231, -0.04701721,\n",
      "       -0.03111491,  0.03066592,  0.00036247,  0.02211001,  0.0453047 ,\n",
      "       -0.00852747, -0.03377901, -0.00070848,  0.02808179, -0.02452698,\n",
      "       -0.01239603, -0.01928671, -0.04927863,  0.00941657, -0.03349509,\n",
      "       -0.0280575 ,  0.02584897, -0.02946255,  0.02440159,  0.01798085,\n",
      "       -0.02668744,  0.02967331, -0.01522707, -0.01164965,  0.04617703,\n",
      "       -0.01714064, -0.03880049, -0.03971137, -0.01671846,  0.00467148,\n",
      "       -0.0033025 ,  0.04709238,  0.03708574,  0.02728449, -0.02324895,\n",
      "        0.03670606, -0.00755475, -0.02045144,  0.04193505, -0.04387125],\n",
      "      dtype=float32), 'brown': array([-6.6175312e-04, -4.3188490e-02, -2.4102582e-02, -1.8871538e-03,\n",
      "       -2.3259401e-02, -3.3987120e-02, -1.1826992e-02,  1.0455370e-02,\n",
      "       -4.6887886e-02, -4.6523582e-02,  1.1904277e-02, -3.0801201e-02,\n",
      "        2.9425509e-03,  1.1928938e-02,  1.6605306e-02,  2.3011453e-03,\n",
      "       -2.1192944e-02,  1.4387120e-02,  4.4205356e-02,  4.0149577e-03,\n",
      "       -2.0758677e-02,  3.2535765e-02, -2.9063035e-02,  4.9891844e-03,\n",
      "       -1.6619682e-02,  2.8766420e-02, -5.0403178e-05, -4.6471506e-04,\n",
      "       -4.4669807e-02,  4.2579640e-02, -1.9380450e-02, -1.6352247e-02,\n",
      "        3.4254994e-02,  3.1341460e-02, -4.9565461e-02, -1.3680529e-02,\n",
      "        2.9784802e-02,  3.3155922e-02,  7.9566240e-03,  3.5061870e-02,\n",
      "        7.4590817e-03, -3.0133128e-03,  4.1880097e-02, -7.5907633e-04,\n",
      "        4.4909827e-03, -1.7213285e-02,  1.2251079e-02,  4.4465158e-02,\n",
      "       -4.4744994e-02,  5.3587072e-03], dtype=float32), 'lazy': array([-9.4452612e-03,  3.1939533e-02,  3.6461007e-02,  4.5424726e-02,\n",
      "        1.1363648e-02,  4.9060453e-02, -2.7349556e-02,  1.1156701e-02,\n",
      "        1.5596937e-02, -2.8435325e-02,  3.3175956e-02,  2.7540255e-02,\n",
      "       -9.0128407e-03, -2.7722621e-02,  3.8981214e-03, -4.1258447e-03,\n",
      "        2.0452272e-02, -3.0410100e-02,  1.1508763e-02, -3.7755836e-02,\n",
      "       -6.9705024e-03, -4.9637072e-03, -2.1853661e-02, -4.4333078e-02,\n",
      "       -1.5025545e-02,  9.5093139e-03,  3.9740983e-02, -6.0910359e-03,\n",
      "       -4.4601094e-02, -1.7060436e-02,  4.5212992e-03, -7.3486194e-03,\n",
      "        1.5669730e-02, -4.0289648e-03,  2.7085211e-02, -8.6359270e-03,\n",
      "        8.3446503e-05,  2.1488581e-02,  1.9116152e-02,  1.1744261e-02,\n",
      "        2.2797100e-03, -1.7106771e-02, -8.7584183e-04,  2.3894202e-02,\n",
      "        9.9022277e-03, -2.1251583e-02, -4.5242023e-02,  4.5626286e-02,\n",
      "       -1.7711055e-02, -4.4181682e-02], dtype=float32), 'red': array([-1.3304390e-02,  3.9110873e-02, -1.6703784e-02,  4.0256012e-02,\n",
      "       -3.4572162e-02,  3.9337762e-03, -1.1285365e-02, -2.6356364e-02,\n",
      "        5.3179488e-03, -4.7274973e-02, -4.8162211e-02,  3.8971234e-02,\n",
      "        6.3261390e-03, -3.0940140e-02,  1.0266472e-02, -8.8450536e-03,\n",
      "       -4.9623251e-02, -4.0531397e-02, -7.1458928e-03, -2.2949625e-02,\n",
      "        2.6895236e-02,  3.3328082e-02, -4.1476846e-02,  2.1906052e-02,\n",
      "        3.8794551e-02,  3.3805594e-03, -4.1969229e-02, -4.3648731e-02,\n",
      "       -7.6316297e-05,  3.5688307e-02,  3.9402176e-02,  4.9240243e-02,\n",
      "       -2.4330068e-02, -1.0294236e-02,  7.9222433e-03, -6.4099431e-03,\n",
      "        4.6850298e-02, -2.9784668e-02,  4.5651946e-02,  2.8003063e-02,\n",
      "        1.4489029e-02,  2.3177456e-02, -1.3887465e-02,  1.1133231e-02,\n",
      "        3.8995076e-02,  3.2017205e-02, -4.8202265e-02, -4.6419382e-02,\n",
      "       -1.9800056e-02,  2.7627621e-02], dtype=float32), 'sleeping': array([-0.0075084 , -0.00818157,  0.01444875, -0.04923774, -0.03152968,\n",
      "       -0.03311308, -0.03510646,  0.02944095,  0.03949856,  0.03450817,\n",
      "        0.01189716,  0.0443287 ,  0.00753225,  0.03662116,  0.00598235,\n",
      "       -0.04784369,  0.03979215,  0.01072532,  0.0356391 ,  0.042263  ,\n",
      "        0.02153978, -0.04400497, -0.03519019, -0.02286568, -0.00195188,\n",
      "       -0.0157245 ,  0.00942775, -0.04486585,  0.00712849, -0.01398971,\n",
      "       -0.02584469, -0.03757801, -0.0326542 , -0.02489477, -0.00774835,\n",
      "       -0.03856046,  0.01578721,  0.03499457, -0.03171907, -0.03509103,\n",
      "       -0.0339806 , -0.03171935, -0.03874273,  0.00370609, -0.00397019,\n",
      "       -0.02319461, -0.02903143,  0.03984255,  0.03305699,  0.04186926],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(word_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
